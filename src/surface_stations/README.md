The project pipeline is defined as a sequence of three steps: (1) data retrieving, (2) data pre-processing and (3) model training. These steps are implemented as Python scripts in the `./src/surface_stations` directory.

#### Weather Station Data Retrieval

All datasets retrieved and/or generated by the scripts will be stored in the `./data` folder.

- **_retrieve_ws_cor.py_**: Retrieves observation from a user-provided weather station.
- **_retrieve_ws_inmet.py_**: Retrieves observations for from a user-provided weather station.

#### Preprocessing

The preprocessing scripts are responsible for performing several operations on the original dataset, such as creating variables or aggregating data, which can be interesting for model training and its final result. 

#### Dataset building

These scripts will build the train, validation and test dataset from the times series produced in the previous steps. These are the datasets to be given as input to the model training step.

#### Model training and evaluation

The model generation script is responsible for performing the training and exporting the results obtained by the model after testing. 
# r2t

## Notebooks

There are several Jupyter Notebooks in the notebooks directory. They were used for initial experiments and explorarory data analisys. These notebooks are not guaranteed to run 100% correctly due to the subsequent code refactor.