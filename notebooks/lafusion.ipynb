{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "Description: Process the GOES-16/17 data\n",
    "Author: Joao Henry Huaman Chinchay\n",
    "E-mail: joaohenry23@gmail.com\n",
    "Created date: Mar 23, 2020\n",
    "Modification date: Jul 23, 2023\n",
    "'''\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset, num2date\n",
    "from pyproj import Proj\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class GOES():\n",
    "\n",
    "\n",
    "    def __init__(self, attrs):\n",
    "        for key in attrs.keys():\n",
    "            setattr(self, key, attrs[key])\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        attr = []\n",
    "        classes = []\n",
    "        var = []\n",
    "        for key in list(self.__dict__.keys()):\n",
    "\n",
    "            if isinstance(self.__dict__[key],np.ndarray):\n",
    "                var.append('   {:29} ({}) {}'.format(key, ', '.join(np.array(self.__dict__[key].shape).astype('str')), str(self.__dict__[key].dtype)))\n",
    "\n",
    "            elif isinstance(self.__dict__[key],GOES):\n",
    "                classes.append('   {:29} {}'.format(key, self.__dict__[key].__class__))\n",
    "\n",
    "            elif isinstance(self.__dict__[key],str):\n",
    "                if len(self.__dict__[key])>50 :\n",
    "                    attrib = '{:.48}...'.format(self.__dict__[key])\n",
    "                else:\n",
    "                    attrib = '{}'.format(self.__dict__[key])\n",
    "                attr.append('   {:30}: {}'.format(key, attrib))\n",
    "\n",
    "            elif isinstance(self.__dict__[key],tuple):\n",
    "                attr.append('   {:30}: ({})'.format(key, ', '.join(self.__dict__[key])))\n",
    "            else:\n",
    "                attr.append('   {:30}: {}'.format(key, self.__dict__[key]))\n",
    "\n",
    "        return '\\n'.join([str(self.__class__)]+['']+['Keys:']+attr+classes+var+[''])\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        attr = []\n",
    "        classes = []\n",
    "        var = []\n",
    "        for key in list(self.__dict__.keys()):\n",
    "\n",
    "            if isinstance(self.__dict__[key],np.ndarray):\n",
    "                var.append('   {:29} ({}) {}'.format(key, ', '.join(np.array(self.__dict__[key].shape).astype('str')), str(self.__dict__[key].dtype)))\n",
    "\n",
    "            elif isinstance(self.__dict__[key],GOES):\n",
    "                classes.append('   {:29} {}'.format(key, self.__dict__[key].__class__))\n",
    "\n",
    "            elif isinstance(self.__dict__[key],str):\n",
    "                if len(self.__dict__[key])>50 :\n",
    "                    attrib = '{:.48}...'.format(self.__dict__[key])\n",
    "                else:\n",
    "                    attrib = '{}'.format(self.__dict__[key])\n",
    "                attr.append('   {:30}: {}'.format(key, attrib))\n",
    "\n",
    "            elif isinstance(self.__dict__[key],tuple):\n",
    "                attr.append('   {:30}: ({})'.format(key, ', '.join(self.__dict__[key])))\n",
    "            else:\n",
    "                attr.append('   {:30}: {}'.format(key, self.__dict__[key]))\n",
    "\n",
    "        return '\\n'.join([str(self.__class__)]+['']+['Keys:']+attr+classes+var+[''])\n",
    "\n",
    "\n",
    "\n",
    "    def refl_fact_to_refl(self, Lons, Lats, MinCosTheta=0.0, fmt=np.float32):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It converts reflectance factor to reflectance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Lons : ndarray\n",
    "            A scalar 2-D array with center longitude of pixel.\n",
    "\n",
    "        Lats : ndarray\n",
    "            A scalar 2-D array with center latitude of pixel.\n",
    "\n",
    "        MinCosTheta : float, optional, default 0.0\n",
    "            Minimum valid value of the cosine of theta.\n",
    "\n",
    "        fmt : dtype, optional, default np.float32\n",
    "            The type of the returns.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        reflectance : object\n",
    "            reflectance.\n",
    "\n",
    "        '''\n",
    "\n",
    "        if self.long_name == 'ABI L2+ Cloud and Moisture Imagery reflectance factor':\n",
    "\n",
    "            try:\n",
    "                assert self.data.shape == Lons.data.shape == Lats.data.shape\n",
    "            except AssertionError:\n",
    "                print('\\n\\tShape of Lon, Lat and data do not match.\\n')\n",
    "                return\n",
    "            else:\n",
    "                dict_Field = {'long_name':'ABI L2+ Cloud and Moisture Imagery reflectance', 'standard_name':'toa_lambertian_equivalent_albedo',\n",
    "                              'units':1, 'undef':np.nan, 'axis':'YX', 't':self.t, 'time_bounds':self.time_bounds, 'pixels_limits':self.pixels_limits, 'dimensions':('y','x'),\n",
    "                              'data':self.data/cosine_of_solar_zenith_angle(Lons.data, Lats.data, self.t.data, MinCosTheta=MinCosTheta, fmt=fmt).data}\n",
    "                return GOES(dict_Field);\n",
    "\n",
    "        else:\n",
    "            print('\\n\\tIt is not possible convert Data because is not ABI L2+ Cloud and Moisture Imagery reflectance factor\\n')\n",
    "\n",
    "\n",
    "\n",
    "    def keys(self):\n",
    "        return list(self.__dict__.keys())\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class open_dataset():\n",
    "\n",
    "    def __init__(self, File):\n",
    "        self.ds = Dataset(File)\n",
    "\n",
    "\n",
    "    def attribute(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets attribute from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of attribute\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Value of attribute\n",
    "\n",
    "        '''\n",
    "\n",
    "        ds = self.ds\n",
    "        try:\n",
    "            assert parameter in ds.ncattrs()\n",
    "        except AssertionError:\n",
    "            print('\\n\\tParameter not found, check if it is an attribute\\n')\n",
    "            return\n",
    "        else:\n",
    "            return getattr(ds,parameter);\n",
    "\n",
    "\n",
    "\n",
    "    def dimension(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets dimension from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of dimension\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameter: str\n",
    "            Value of dimension\n",
    "\n",
    "        '''\n",
    "\n",
    "        ds = self.ds\n",
    "        try:\n",
    "            assert parameter in ds.dimensions.keys()\n",
    "        except AssertionError:\n",
    "            print('\\n\\tParameter not found, check if it is a dimension\\n')\n",
    "            return\n",
    "        else:\n",
    "            parameter = ds.dimensions[parameter]\n",
    "            return GOES({'name':parameter.name, 'size':parameter.size});\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def group(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets group from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of group\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameter: str\n",
    "            Value of group\n",
    "\n",
    "        '''\n",
    "\n",
    "        ds = self.ds\n",
    "        try:\n",
    "            assert parameter in ds.groups.keys()\n",
    "        except AssertionError:\n",
    "            print('\\n\\tParameter not found, check if it is a group\\n')\n",
    "            return\n",
    "        else:\n",
    "            return ds.groups[parameter];\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def variable(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets variable from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of variable\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameter: str\n",
    "            Value of variable\n",
    "\n",
    "        '''\n",
    "\n",
    "        ds = self.ds\n",
    "        try:\n",
    "            assert parameter in ds.variables.keys()\n",
    "        except AssertionError:\n",
    "            print('\\n\\tParameter not found, check if it is a variable\\n')\n",
    "            return\n",
    "        else:\n",
    "            try:\n",
    "                assert ds.variables[parameter].dimensions != ('y','x') #(ds.variables[parameter].ndim == 0) or (ds.variables[parameter].ndim == 1)\n",
    "            except AssertionError:\n",
    "                print('\\n\\tParameter is not a variable\\n')\n",
    "                return\n",
    "            else:\n",
    "                parameter = ds.variables[parameter]\n",
    "                fmt = parameter[:].dtype\n",
    "                data = np.where(parameter[:].mask==True, np.nan, parameter[:].data)\n",
    "                IsDateTime = False\n",
    "\n",
    "                if 'units' in parameter.ncattrs():\n",
    "                    if 'seconds since' in parameter.units:\n",
    "                        data = num2date(data, parameter.units, 'standard', only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "                        fmt = object\n",
    "                        data = np.array(data)\n",
    "                        IsDateTime = True\n",
    "                        #if isinstance(data, np.ma.core.MaskedArray):\n",
    "                        #    data = np.array(data)\n",
    "                        #if isinstance(data, datetime.datetime):\n",
    "                        #    data = np.array(data)\n",
    "                else:\n",
    "                    if 'long_name' in parameter.ncattrs():\n",
    "                        if 'seconds since' in parameter.long_name or 'time' in parameter.long_name:\n",
    "                            if '(' and ')' in parameter.long_name:\n",
    "                                units = 'seconds since '+re.findall(r'\\(.+?\\)',parameter.long_name)[0][1:-1]\n",
    "                            else:\n",
    "                                units = 'seconds since 2000-01-01 12:00:00'\n",
    "                            data = num2date(data, units, 'standard', only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "                            fmt = object\n",
    "                            data = np.array(data)\n",
    "                            IsDateTime = True\n",
    "                            #if isinstance(data, np.ma.core.MaskedArray):\n",
    "                            #    data = np.array(data)\n",
    "                            #if isinstance(data, datetime.datetime):\n",
    "                            #    data = np.array(data)\n",
    "\n",
    "                dict = {}\n",
    "                for key in parameter.__dict__.keys():\n",
    "                    dict.update({key: getattr(parameter,key)})\n",
    "\n",
    "                if IsDateTime == True:\n",
    "                    if 'units' in dict:\n",
    "                        del dict['units']\n",
    "\n",
    "                for item in ['_Unsigned','scale_factor','add_offset','_FillValue']:\n",
    "                    if item in dict:\n",
    "                        del dict[item]\n",
    "\n",
    "                dict.update({'dimensions': getattr(parameter,'dimensions')})\n",
    "\n",
    "                if data.ndim == 0:\n",
    "                    data = data.reshape([1])\n",
    "                    dict.update({'data':data[0]})\n",
    "                else:\n",
    "                    dict.update({'data':data.astype(fmt)})\n",
    "\n",
    "                return GOES(dict);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def image(self, parameter, lonlat='center', domain=None, domain_in_pixels=None, up_level=False, nan_mask=None, delta_index=4, fmt=np.float32):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets image from dataset with its longitude and latitude information.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter : str\n",
    "            Name of image.\n",
    "\n",
    "        lonlat: str, optional, default 'center'\n",
    "            Define if longitud and latitud of parameter are return.\n",
    "            If lonlat='center' return center of each pixel of parameter.\n",
    "            If lonlat='corner' return corners of each of pixel parameter.\n",
    "            If lonlat=None return None values instead of latitud and longitud.\n",
    "\n",
    "        domain : list or None, optional, default None\n",
    "            List with coordinates of domain that you want to select.\n",
    "            Example:\n",
    "            domain = [LLLon, URLon, LLLat, URLat]\n",
    "                 \n",
    "            Where:\n",
    "\n",
    "                LLLon : float\n",
    "                          Lower left longitude of domain.\n",
    "\n",
    "                URLon : float\n",
    "                          Upper right longitude of domain.\n",
    "\n",
    "                LLLat : float\n",
    "                          Lower left latitude of domain.\n",
    "\n",
    "                URLat : float\n",
    "                          Upper right latitude of domain.\n",
    "\n",
    "\n",
    "        domain_in_pixels : list, numpy.ndarray or None, optional, default None\n",
    "            List or numpy.ndarray with the pixels position index of domain that\n",
    "            you want to select.\n",
    "            Example:\n",
    "            domain_in_pixels = [XMIN, XMAX, YMIN, YMAX]\n",
    "                 \n",
    "            Where:\n",
    "\n",
    "                XMIN : int\n",
    "                          Lower left pixel of domain.\n",
    "\n",
    "                XMAX : int\n",
    "                          Upper right pixel of domain.\n",
    "\n",
    "                YMIN : int\n",
    "                          Lower left pixel of domain.\n",
    "\n",
    "                YMAX : int\n",
    "                          Upper right pixel of domain.\n",
    "\n",
    "\n",
    "        up_level : boolean, optional, default False\n",
    "            If parameter is an L1b ABI channel (Rad), then up_level=True\n",
    "            convert this parameter to L2 product. If this parameter correspond\n",
    "            to channels 01-06, the L2 product will be the Reflectance Factor,\n",
    "            but if correspond to channels 07-16, then L2 product will be the\n",
    "            brightness temperature.\n",
    "\n",
    "        nan_mask : numpy.ndarray or None, optional, default None\n",
    "            When lonlat=None, the latitude and longitude information is absent,\n",
    "            which prevents to know the image pixels with incorrect geographic\n",
    "            information. To solved this, nan_mask must be a np.ndarray with\n",
    "            True or False values and it must be the same size as the returned\n",
    "            image. The True values of nan_mask indicate the image pixels that\n",
    "            will be convert to nan. If nan_mask=None, nothing is done.\n",
    "\n",
    "        delta_index : int, optional, default 4\n",
    "            Interval between indexes of arrays, used to locate\n",
    "            more quickly the index of satellite region that will be slice.\n",
    "\n",
    "        fmt : dtype, optional, default np.float32\n",
    "            The type of the returns (Field, Lons and Lats).\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Field : object\n",
    "            A scalar 2-D array.\n",
    "\n",
    "        Lons : object\n",
    "            A scalar 2-D array with longitude of Field.\n",
    "\n",
    "        Lats : object\n",
    "            A scalar 2-D array with latitude of Field.\n",
    "\n",
    "        '''\n",
    "\n",
    "        ds = self.ds\n",
    "\n",
    "        try:\n",
    "            assert parameter in ds.variables.keys()\n",
    "        except AssertionError:\n",
    "            print('\\n\\tParameter not found, check if it is an image\\n')\n",
    "            return\n",
    "        else:\n",
    "\n",
    "            try:\n",
    "                assert ('y','x') == ds.variables[parameter].dimensions\n",
    "            except AssertionError:\n",
    "                print(\"\\n\\t{} is not a valid product because have not ('y','x') dimensions\\n\".format(parameter))\n",
    "                return\n",
    "            else:\n",
    "                ProcessingLevel = ds.processing_level.split(' ')[-1]\n",
    "                PlatformID = ds.platform_ID\n",
    "                SatHeight = ds.variables['goes_imager_projection'].perspective_point_height\n",
    "                SatLon = ds.variables['goes_imager_projection'].longitude_of_projection_origin\n",
    "                SatSweep = ds.variables['goes_imager_projection'].sweep_angle_axis\n",
    "\n",
    "                X = ds.variables['x']\n",
    "                Y = ds.variables['y']\n",
    "                xsize = X.shape[0]\n",
    "                ysize = Y.shape[0]\n",
    "                #------------------------------------------------------------------\n",
    "                # gets attributes of Field\n",
    "                dict_Field = {'long_name':None, 'standard_name':None,\n",
    "                              'units':None, 'undef':np.nan, 'pixels_limits':None, 'axis':'YX',\n",
    "                              't':None, 'time_bounds':None, 'dimensions':('y','x'), 'data':None}\n",
    "\n",
    "                dict_Field['t'] = self.variable('t')\n",
    "                dict_Field['time_bounds'] = self.variable('time_bounds')\n",
    "\n",
    "                #------------------------------------------------------------------\n",
    "\n",
    "                for item in ds.variables[parameter].ncattrs():\n",
    "                    if item in dict_Field.keys():\n",
    "                        dict_Field[item] = getattr(ds.variables[parameter],item)\n",
    "\n",
    "                #------------------------------------------------------------------\n",
    "\n",
    "                if isinstance(domain, list) or isinstance(domain, np.ndarray):\n",
    "\n",
    "                    LLLon, URLon, LLLat, URLat = domain\n",
    "                    Lons, Lats = get_lonlat(X[::delta_index].astype(fmt), Y[::delta_index].astype(fmt), PlatformID, SatLon, SatHeight, SatSweep, fmt=fmt)\n",
    "\n",
    "                    xpixmin, xpixmax, ypixmin, ypixmax = find_pixels_of_region(Lons, Lats, LLLon, URLon, LLLat, URLat)\n",
    "                    del Lons, Lats\n",
    "\n",
    "                    xini = xpixmin*delta_index\n",
    "                    xfin = (xpixmax+1)*delta_index -1\n",
    "                    yini = ypixmin*delta_index\n",
    "                    yfin = (ypixmax+1)*delta_index -1\n",
    "\n",
    "                    #- - - - - - - - - - - - - - - - - - -\n",
    "                    # add and decrease pixels to improve the search of pixels of interest region\n",
    "                    if xini - delta_index < 0:\n",
    "                        xini = 0\n",
    "                    else:\n",
    "                        xini = xini - delta_index\n",
    "\n",
    "\n",
    "                    if xfin + delta_index > xsize-1:\n",
    "                        xfin = xsize-1\n",
    "                    else:\n",
    "                        xfin = xfin + delta_index\n",
    "\n",
    "\n",
    "\n",
    "                    if yini - delta_index < 0:\n",
    "                        yini = 0\n",
    "                    else:\n",
    "                        yini = yini - delta_index\n",
    "\n",
    "\n",
    "                    if yfin + delta_index > ysize-1:\n",
    "                        yfin = ysize-1\n",
    "                    else:\n",
    "                        yfin = yfin + delta_index\n",
    "\n",
    "                    #- - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "                    Lons, Lats = get_lonlat(X[xini:xfin+1].astype(fmt), Y[yini:yfin+1].astype(fmt), PlatformID, SatLon, SatHeight, SatSweep, fmt=fmt)\n",
    "\n",
    "                    xpixmin, xpixmax, ypixmin, ypixmax = find_pixels_of_region(Lons, Lats, LLLon, URLon, LLLat, URLat)\n",
    "                    Limits = np.array([xini+xpixmin, xini+xpixmax, yini+ypixmin, yini+ypixmax])\n",
    "                    dict_Field['pixels_limits'] = Limits\n",
    "\n",
    "\n",
    "                    if lonlat == 'center':\n",
    "                        del X, Y\n",
    "                        dict_Lons = Lons\n",
    "                        dict_Lats = Lats\n",
    "                        dict_Lons.data = np.ascontiguousarray(Lons.data[ypixmin:ypixmax+1,xpixmin:xpixmax+1], dtype=fmt)\n",
    "                        dict_Lats.data = np.ascontiguousarray(Lats.data[ypixmin:ypixmax+1,xpixmin:xpixmax+1], dtype=fmt)\n",
    "\n",
    "                    elif lonlat == 'corner':\n",
    "                        Lons, Lats = get_lonlatcorner(X[xini+xpixmin:xini+xpixmax+1].astype(fmt), Y[yini+ypixmin:yini+ypixmax+1].astype(fmt), PlatformID, SatLon, SatHeight, SatSweep, fmt=fmt)\n",
    "                        del X, Y\n",
    "                        dict_Lons = Lons\n",
    "                        dict_Lats = Lats\n",
    "\n",
    "\n",
    "                elif isinstance(domain_in_pixels, list) or isinstance(domain_in_pixels, np.ndarray):\n",
    "\n",
    "                    xpixmin, xpixmax, ypixmin, ypixmax = domain_in_pixels\n",
    "                    Limits = np.array([xpixmin, xpixmax, ypixmin, ypixmax])\n",
    "                    dict_Field['pixels_limits'] = Limits\n",
    "\n",
    "                    if lonlat == 'center':\n",
    "                        Lons, Lats = get_lonlat(X[xpixmin:xpixmax+1].astype(fmt), Y[ypixmin:ypixmax+1].astype(fmt), PlatformID, SatLon, SatHeight, SatSweep, fmt=fmt)\n",
    "                        del X, Y\n",
    "                        dict_Lons = Lons\n",
    "                        dict_Lats = Lats\n",
    "\n",
    "                    elif lonlat == 'corner':\n",
    "                        Lons, Lats = get_lonlatcorner(X[xpixmin:xpixmax+1].astype(fmt), Y[ypixmin:ypixmax+1].astype(fmt), PlatformID, SatLon, SatHeight, SatSweep, fmt=fmt)\n",
    "                        del X, Y\n",
    "                        dict_Lons = Lons\n",
    "                        dict_Lats = Lats\n",
    "\n",
    "                else:\n",
    "\n",
    "                    xpixmin, xpixmax, ypixmin, ypixmax = 0, xsize-1, 0, ysize-1\n",
    "                    Limits = np.array([xpixmin, xpixmax, ypixmin, ypixmax])\n",
    "                    dict_Field['pixels_limits'] = Limits\n",
    "\n",
    "                    if lonlat == 'center':\n",
    "                        Lons, Lats = get_lonlat(X[:].astype(fmt), Y[:].astype(fmt), PlatformID, SatLon, SatHeight, SatSweep, fmt=fmt)\n",
    "                        del X, Y\n",
    "                        dict_Lons = Lons\n",
    "                        dict_Lats = Lats\n",
    "\n",
    "                    elif lonlat == 'corner':\n",
    "                        Lons, Lats = get_lonlatcorner(X[:].astype(fmt), Y[:].astype(fmt), PlatformID, SatLon, SatHeight, SatSweep, fmt=fmt)\n",
    "                        del X, Y\n",
    "                        dict_Lons = Lons\n",
    "                        dict_Lats = Lats\n",
    "\n",
    "                #------------------------------------------------------------------\n",
    "\n",
    "                if up_level == True:\n",
    "\n",
    "                    try:\n",
    "                        assert ProcessingLevel == 'L1b'\n",
    "                    except AssertionError:\n",
    "                        print('\\n\\tWas not possible increase level of {} because is not L1b.\\n'.format(parameter))\n",
    "                        return\n",
    "                    else:\n",
    "                        if ds.variables['band_id'][0].data < 7:\n",
    "                            dict_Field['long_name'] = 'ABI L2+ Cloud and Moisture Imagery reflectance factor'\n",
    "                            dict_Field['standard_name'] = 'toa_lambertian_equivalent_albedo_multiplied_by_cosine_solar_zenith_angle'\n",
    "                            dict_Field['units'] = '1'\n",
    "                            kappa = ds.variables['kappa0'][:]\n",
    "                            Field = kappa*ds.variables[parameter][Limits[2]:Limits[3]+1,Limits[0]:Limits[1]+1].astype(dtype=fmt)\n",
    "                        else:\n",
    "                            dict_Field['long_name'] = 'ABI L2+ Cloud and Moisture Imagery brightness temperature'\n",
    "                            dict_Field['standard_name'] = 'toa_brightness_temperature'\n",
    "                            dict_Field['units'] = 'K'\n",
    "                            planck_fk1 = ds.variables['planck_fk1'][:]\n",
    "                            planck_fk2 = ds.variables['planck_fk2'][:]\n",
    "                            planck_bc1 = ds.variables['planck_bc1'][:]\n",
    "                            planck_bc2 = ds.variables['planck_bc2'][:]\n",
    "                            Field = (planck_fk2/(np.log( (planck_fk1/ds.variables[parameter][Limits[2]:Limits[3]+1,Limits[0]:Limits[1]+1].astype(dtype=fmt)) +1 )) - planck_bc1)/planck_bc2\n",
    "\n",
    "                else:\n",
    "                    dict_Field['long_name'] = ds.variables[parameter].long_name\n",
    "                    dict_Field['standard_name'] = ds.variables[parameter].standard_name\n",
    "                    dict_Field['units'] = ds.variables[parameter].units\n",
    "                    Field = ds.variables[parameter][Limits[2]:Limits[3]+1,Limits[0]:Limits[1]+1].astype(dtype=fmt)\n",
    "\n",
    "                #------------------------------------------------------------------\n",
    "\n",
    "                if lonlat == 'center':\n",
    "                    Field = np.where((Field[:].mask==True)|(Lons.data==-999.99), np.nan, Field[:])\n",
    "                    Field = np.ascontiguousarray(Field, dtype=fmt)\n",
    "                    dict_Field['data'] = Field\n",
    "                    return GOES(dict_Field), dict_Lons, dict_Lats;\n",
    "\n",
    "                elif lonlat == 'corner':\n",
    "                    mask = np.where(Lons.data<-990.0, True, False)\n",
    "                    mask = corner_size_to_center_size(mask)\n",
    "                    Field = np.where((Field[:].mask==True)|(mask==True), np.nan, Field[:])\n",
    "                    Field = np.ascontiguousarray(Field, dtype=fmt)\n",
    "                    dict_Field['data'] = Field\n",
    "                    return GOES(dict_Field), dict_Lons, dict_Lats;\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if isinstance(nan_mask,np.ndarray):\n",
    "                        if Field[:].size == nan_mask.size:\n",
    "                            Field = np.where((Field[:].mask==True)|(nan_mask==True), np.nan, Field[:])\n",
    "                        else:\n",
    "                            print('The size of the nan_mask does not match the size of the returned image. Masking will not be done.')\n",
    "                            Field = np.where((Field[:].mask==True), np.nan, Field[:])\n",
    "                    else:\n",
    "                        Field = np.where((Field[:].mask==True), np.nan, Field[:])\n",
    "\n",
    "                    Field = np.ascontiguousarray(Field, dtype=fmt)\n",
    "                    dict_Field['data'] = Field\n",
    "                    dict_Lons = None\n",
    "                    dict_Lats = None\n",
    "                    return GOES(dict_Field), None, None;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        ds = self.ds\n",
    "        attr = ['attribute:']\n",
    "        dims = ['dimension:']\n",
    "        var0D = ['variable:']\n",
    "        var1D = []\n",
    "        var2D = []\n",
    "        varMD = []\n",
    "        image = ['image:']\n",
    "        group = ['group:']\n",
    "\n",
    "        for item in ds.ncattrs():\n",
    "            attrib = getattr(ds,item)\n",
    "            if len(attrib)>50 :\n",
    "                attrib = '{:.48}...'.format(attrib)\n",
    "            attr.append('   {:30}: {}'.format(item, attrib))\n",
    "\n",
    "        for item in ds.dimensions.keys():\n",
    "            dims.append('   {:50} ({})'.format(item, ds.dimensions[item].size))\n",
    "\n",
    "        for item in ds.variables.keys():\n",
    "            if ds.variables[item].ndim == 0:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var0D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 1:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var1D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 2:\n",
    "                if ds.variables[item].dimensions == ('y','x') :\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    image.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "                else:\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    var2D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim > 2:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                varMD.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "\n",
    "        for item in ds.groups.keys():\n",
    "            groups.append('   {:50}'.format(item))\n",
    "\n",
    "        return '\\n'.join([str(self.__class__)]+['']+attr+['']+dims+['']+var0D+var1D+var2D+varMD+['']+image+['']+group+[''])\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        ds = self.ds\n",
    "        attr = ['attribute:']\n",
    "        dims = ['dimension:']\n",
    "        var0D = ['variable:']\n",
    "        var1D = []\n",
    "        var2D = []\n",
    "        varMD = []\n",
    "        image = ['image:']\n",
    "        group = ['group:']\n",
    "\n",
    "        for item in ds.ncattrs():\n",
    "            attrib = getattr(ds,item)\n",
    "            if len(attrib)>50 :\n",
    "                attrib = '{:.48}...'.format(attrib)\n",
    "            attr.append('   {:30}: {}'.format(item, attrib))\n",
    "\n",
    "        for item in ds.dimensions.keys():\n",
    "            dims.append('   {:50} ({})'.format(item, ds.dimensions[item].size))\n",
    "\n",
    "        for item in ds.variables.keys():\n",
    "            if ds.variables[item].ndim == 0:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var0D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 1:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var1D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 2:\n",
    "                if ds.variables[item].dimensions == ('y','x') :\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    image.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "                else:\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    var2D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim > 2:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                varMD.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "\n",
    "        for item in ds.groups.keys():\n",
    "            groups.append('   {:50}'.format(item))\n",
    "\n",
    "        return '\\n'.join([str(self.__class__)]+['']+attr+['']+dims+['']+var0D+var1D+var2D+varMD+['']+image+['']+group+[''])\n",
    "\n",
    "\n",
    "\n",
    "    def keys(self):\n",
    "        return list(self.__dict__.keys())\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class open_mfdataset():\n",
    "\n",
    "    def __init__(self, FList):\n",
    "        try:\n",
    "            assert isinstance(FList,list)\n",
    "        except AssertionError:\n",
    "            print('\\n\\tFList must be a list\\n')\n",
    "            return\n",
    "        else:\n",
    "            ds = []\n",
    "            for File in FList:\n",
    "                try:\n",
    "                    assert 'GLM' in File\n",
    "                except AssertionError:\n",
    "                    print('\\n\\topen_mfdataset just work with GLM files\\n')\n",
    "                    return\n",
    "                else:\n",
    "                    ds.append(Dataset(File))\n",
    "\n",
    "            self.ds = ds\n",
    "            self.files = FList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def attribute(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets attribute from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of attribute\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Value of attribute\n",
    "\n",
    "        '''\n",
    "\n",
    "        mfparameter = []\n",
    "        for idx in range(len(self.ds)):\n",
    "            ds = self.ds[idx]\n",
    "            try:\n",
    "                assert parameter in ds.ncattrs()\n",
    "            except AssertionError:\n",
    "                print('\\n\\tParameter not found, check if it is an attribute\\n')\n",
    "                return\n",
    "            else:\n",
    "                mfparameter.append(getattr(ds,parameter))\n",
    "        return mfparameter;\n",
    "\n",
    "\n",
    "\n",
    "    def dimension(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets dimension from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of dimension\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameter: str\n",
    "            Value of dimension\n",
    "\n",
    "        '''\n",
    "\n",
    "        mfparameter_name = []\n",
    "        mfparameter_size = []\n",
    "        for idx in range(len(self.ds)):\n",
    "            ds = self.ds[idx]\n",
    "            try:\n",
    "                assert parameter in ds.dimensions.keys()\n",
    "            except AssertionError:\n",
    "                print('\\n\\tParameter not found, check if it is a dimension\\n')\n",
    "                print(list(ds.dimensions.keys()))\n",
    "                return\n",
    "            else:\n",
    "                mfparameter_name.append(ds.dimensions[parameter].name)\n",
    "                mfparameter_size.append(ds.dimensions[parameter].size)\n",
    "        return GOES({'name':np.array(mfparameter_name), 'size':np.array(mfparameter_size)});\n",
    "\n",
    "\n",
    "\n",
    "    def group(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets group from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of group\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameter: str\n",
    "            Value of group\n",
    "\n",
    "        '''\n",
    "\n",
    "        mfparameter = []\n",
    "        for idx in range(len(self.ds)):\n",
    "            ds = self.ds[idx]\n",
    "            try:\n",
    "                assert parameter in ds.groups.keys()\n",
    "            except AssertionError:\n",
    "                print('\\n\\tParameter not found, check if it is a group\\n')\n",
    "                return\n",
    "            else:\n",
    "                mfparameter.append(ds.groups[parameter])\n",
    "        return mfparameter;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def variable(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets variable from file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter: str\n",
    "            Name of variable\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        parameter: str\n",
    "            Value of variable\n",
    "\n",
    "        '''\n",
    "\n",
    "        for idx in range(len(self.ds)):\n",
    "            ds = self.ds[idx]\n",
    "            try:\n",
    "                assert parameter in ds.variables.keys()\n",
    "            except AssertionError:\n",
    "                print('\\n\\tParameter not found, check if it is a variable\\n')\n",
    "                return\n",
    "            else:\n",
    "                try:\n",
    "                    assert ds.variables[parameter].dimensions != ('y','x')\n",
    "                    #assert (ds.variables[parameter].ndim == 0) or (ds.variables[parameter].ndim == 1)\n",
    "                except AssertionError:\n",
    "                    print('\\n\\tParameter is not a variable\\n')\n",
    "                    return\n",
    "                else:\n",
    "                    mfparameter = ds.variables[parameter]\n",
    "                    fmt = mfparameter[:].dtype\n",
    "                    data = np.where(mfparameter[:].mask==True, np.nan, mfparameter[:].data)\n",
    "                    IsDateTime = False\n",
    "\n",
    "                    if 'units' in mfparameter.ncattrs():\n",
    "                        if 'seconds since' in mfparameter.units:\n",
    "                            data = num2date(data, mfparameter.units, 'standard', only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "                            fmt = object\n",
    "                            data = np.array(data)\n",
    "                            IsDateTime = True\n",
    "                            #if isinstance(data, np.ma.core.MaskedArray):\n",
    "                            #    data = np.array(data)\n",
    "                            #if isinstance(data, datetime.datetime):\n",
    "                            #    data = np.array(data)#([data])\n",
    "                    else:\n",
    "                        if 'long_name' in mfparameter.ncattrs():\n",
    "                            if 'seconds since' in mfparameter.long_name or 'time' in mfparameter.long_name:\n",
    "                                if '(' and ')' in mfparameter.long_name:\n",
    "                                    units = 'seconds since '+re.findall(r'\\(.+?\\)',mfparameter.long_name)[0][1:-1]\n",
    "                                else:\n",
    "                                    units = 'seconds since 2000-01-01 12:00:00'\n",
    "                                data = num2date(data, units, 'standard', only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "                                fmt = object\n",
    "                                data = np.array(data)\n",
    "                                IsDateTime = True\n",
    "                                #if isinstance(data, np.ma.core.MaskedArray):\n",
    "                                #    data = np.array(data)\n",
    "                                #if isinstance(data, datetime.datetime):\n",
    "                                #    data = np.array(data)#([data])\n",
    "\n",
    "                    if data.ndim == 0:\n",
    "                        data = data.reshape([1]) #np.array([data])\n",
    "                    elif data.ndim == 1:\n",
    "                        if 'bounds' in mfparameter.dimensions[0]:\n",
    "                            data = data.reshape([1,2])\n",
    "\n",
    "            if idx == 0 :\n",
    "                mfdata = data\n",
    "            else:\n",
    "                mfdata = np.concatenate((mfdata,data))\n",
    "\n",
    "        dict = {}\n",
    "        for key in mfparameter.__dict__.keys():\n",
    "            dict.update({key: getattr(mfparameter,key)})\n",
    "\n",
    "        if IsDateTime == True:\n",
    "            if 'units' in dict:\n",
    "                del dict['units']\n",
    "\n",
    "        for item in ['_Unsigned','scale_factor','add_offset','_FillValue']:\n",
    "            if item in dict:\n",
    "                del dict[item]\n",
    "\n",
    "        if len(getattr(mfparameter,'dimensions')) == 0:\n",
    "            dict.update({'dimensions': ('number_of_files',)})\n",
    "        elif len(getattr(mfparameter,'dimensions')) == 1:\n",
    "            if 'bounds' in mfparameter.dimensions[0]:\n",
    "                dict.update({'dimensions': ('number_of_files',getattr(mfparameter,'dimensions')[0])})\n",
    "            else:\n",
    "                dict.update({'dimensions': getattr(mfparameter,'dimensions')})\n",
    "        else:\n",
    "            dict.update({'dimensions': getattr(mfparameter,'dimensions')})\n",
    "\n",
    "        dict.update({'data':mfdata.astype(fmt)})\n",
    "\n",
    "        return GOES(dict);\n",
    "\n",
    "\n",
    "\n",
    "    def image(self, parameter):\n",
    "\n",
    "        '''\n",
    "\n",
    "        It gets image from file, however, in this case, this method is disable because the files was open with open_mfdataset().\n",
    "\n",
    "        '''\n",
    "        print('\\nThe image() method is disable for open_mfdataset(). Open the file with open_dataset() if you wan to use the image() method.\\n')\n",
    "        return None, None, None;\n",
    "\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        nfiles = len(self.ds) #for idx in range(len(self.ds)):\n",
    "        ds = self.ds[0]\n",
    "        nf = ['number files: '+str(nfiles)]\n",
    "        files = self.files\n",
    "        attr = ['attribute:']\n",
    "        dims = ['dimension:']\n",
    "        var0D = ['variable:']\n",
    "        var1D = []\n",
    "        var2D = []\n",
    "        varMD = []\n",
    "        image = ['image:']\n",
    "        group = ['group:']\n",
    "\n",
    "        for item in ds.ncattrs():\n",
    "            attr.append('   {:30}'.format(item))\n",
    "\n",
    "        for item in ds.dimensions.keys():\n",
    "            dims.append('   {:50}'.format(item))\n",
    "\n",
    "        for item in ds.variables.keys():\n",
    "            if ds.variables[item].ndim == 0:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var0D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 1:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var1D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 2:\n",
    "                if ds.variables[item].dimensions == ('y','x'):\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    image.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "                else:\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    var2D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim > 2:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                varMD.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "\n",
    "        for item in ds.groups.keys():\n",
    "            groups.append('   {:50}'.format(item))\n",
    "\n",
    "        return '\\n'.join([str(self.__class__)]+['']+nf+files+['']+attr+['']+dims+['']+var0D+var1D+var2D+varMD+['']+image+['']+group+[''])\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        nfiles = len(self.ds) #for idx in range(len(self.ds)):\n",
    "        ds = self.ds[0]\n",
    "        nf = ['number files: '+str(nfiles)]\n",
    "        files = self.files\n",
    "        attr = ['attribute:']\n",
    "        dims = ['dimension:']\n",
    "        var0D = ['variable:']\n",
    "        var1D = []\n",
    "        var2D = []\n",
    "        varMD = []\n",
    "        image = ['image:']\n",
    "        group = ['group:']\n",
    "\n",
    "        for item in ds.ncattrs():\n",
    "            attr.append('   {:30}'.format(item))\n",
    "\n",
    "        for item in ds.dimensions.keys():\n",
    "            dims.append('   {:50}'.format(item))\n",
    "\n",
    "        for item in ds.variables.keys():\n",
    "            if ds.variables[item].ndim == 0:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var0D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 1:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                var1D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim == 2:\n",
    "                if ds.variables[item].dimensions == ('y','x'):\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    image.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "                else:\n",
    "                    size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                    var2D.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "            elif ds.variables[item].ndim > 2:\n",
    "                size = '({})'.format(', '.join(ds.variables[item].dimensions))\n",
    "                varMD.append('   {:50} {} {}'.format(item, size, ds.variables[item].dtype))\n",
    "\n",
    "        for item in ds.groups.keys():\n",
    "            groups.append('   {:50}'.format(item))\n",
    "\n",
    "        return '\\n'.join([str(self.__class__)]+['']+nf+files+['']+attr+['']+dims+['']+var0D+var1D+var2D+varMD+['']+image+['']+group+[''])\n",
    "\n",
    "\n",
    "\n",
    "    def keys(self):\n",
    "        return list(self.__dict__.keys())\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_lonlat(X, Y, PlatformID, SatLon, SatHeight, SatSweep, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Calculates the longitude and latitude of the center of the pixels,\n",
    "    corresponding to the satellite image, using the fixed grid East/West and\n",
    "    North/South scanning angle in radians of pixels.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        A scalar 1-D array with the fixed grid East/West scanning\n",
    "        angle in radians.\n",
    "\n",
    "    Y : ndarray\n",
    "        A scalar 1-D array with the fixed grid North/South scanning\n",
    "        angle in radians.\n",
    "\n",
    "    PlatformID : str\n",
    "        Platform ID of satelite. Example: 'G16', 'G17' or 'G18'.\n",
    "\n",
    "    SatLon : float\n",
    "        Longitude of satellite in the nadir.\n",
    "\n",
    "    SatHeight : float\n",
    "        Height of satellite in meters.\n",
    "\n",
    "    SatSweep : str\n",
    "        Sweep-angle axis.\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Lons : dict\n",
    "        Scalar 2-D array with the center longitude of the pixels.\n",
    "        Undefined data are set as -999.99.\n",
    "\n",
    "    Lats : dict\n",
    "        Scalar 2-D array with the center latitude of the pixels.\n",
    "        Undefined data are set as -999.99.\n",
    "\n",
    "    '''\n",
    "\n",
    "    X = X[:]*SatHeight\n",
    "    Y = Y[:]*SatHeight\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    proj = Proj(proj='geos', h=SatHeight, lon_0=SatLon, sweep=SatSweep)\n",
    "    Lons, Lats = proj(X, Y, inverse=True)\n",
    "\n",
    "    if PlatformID == 'G17' or PlatformID == 'G18':\n",
    "        Lons = np.where(Lons>0,Lons-360,Lons)\n",
    "\n",
    "    Lons = np.where((Lons>=-360.0)&(Lons<=360.0)&(Lats>=-90.0)&(Lats<=90.0),Lons,-999.99).astype(fmt)\n",
    "    Lats = np.where((Lons>=-360.0)&(Lons<=360.0)&(Lats>=-90.0)&(Lats<=90.0),Lats,-999.99).astype(fmt)\n",
    "\n",
    "    dict_Lons = {'long_name':'Longitude of center of pixels', 'standard_name':'pixels center longitude',\n",
    "                 'units':'degrees_east', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':Lons}\n",
    "\n",
    "    dict_Lats = {'long_name':'Latitude of center of pixels', 'standard_name':'pixels center latitude',\n",
    "                 'units':'degrees_north', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':Lats}\n",
    "\n",
    "    return GOES(dict_Lons), GOES(dict_Lats);\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_lonlatcorner(X, Y, PlatformID, SatLon, SatHeight, SatSweep, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Calculates the longitude and latitude of the corners of the pixels,\n",
    "    corresponding to the satellite image, using the fixed grid East/West and\n",
    "    North/South scanning angle in radians of pixels.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        A scalar 1-D array with the fixed grid East/West scanning\n",
    "        angle in radians.\n",
    "\n",
    "    Y : ndarray\n",
    "        A scalar 1-D array with the fixed grid North/South scanning\n",
    "        angle in radians.\n",
    "\n",
    "    PlatformID : str\n",
    "        Platform ID of satelite. Example: 'G16', 'G17' or 'G18'.\n",
    "\n",
    "    SatLon : float\n",
    "        Longitude of satellite in the nadir.\n",
    "\n",
    "    SatHeight : float\n",
    "        Height of satellite in meters.\n",
    "\n",
    "    SatSweep : str\n",
    "        Sweep-angle axis.\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Lons : dict\n",
    "        Scalar 2-D array with the center longitude of the pixels.\n",
    "        Undefined data are set as -999.99.\n",
    "\n",
    "    Lats : dict\n",
    "        Scalar 2-D array with the center latitude of the pixels.\n",
    "        Undefined data are set as -999.99.\n",
    "\n",
    "    '''\n",
    "\n",
    "    X = X[:]*SatHeight\n",
    "    Y = Y[:]*SatHeight\n",
    "    dx = X[1]-X[0]\n",
    "    dy = Y[1]-Y[0]\n",
    "    XCor = np.concatenate([X, [X[-1]+dx]])-dx/2\n",
    "    YCor = np.concatenate([Y, [Y[-1]+dy]])-dy/2\n",
    "    XCor, YCor = np.meshgrid(XCor, YCor)\n",
    "    proj = Proj(proj='geos', h=SatHeight, lon_0=SatLon, sweep=SatSweep)\n",
    "    Lons, Lats = proj(XCor, YCor, inverse=True)\n",
    "\n",
    "    if PlatformID == 'G17' or PlatformID == 'G18':\n",
    "        Lons = np.where(Lons>0,Lons-360,Lons)\n",
    "\n",
    "    Lons = np.where((Lons>=-360.0)&(Lons<=360.0)&(Lats>=-90.0)&(Lats<=90.0),Lons,-999.99).astype(fmt)\n",
    "    Lats = np.where((Lons>=-360.0)&(Lons<=360.0)&(Lats>=-90.0)&(Lats<=90.0),Lats,-999.99).astype(fmt)\n",
    "\n",
    "    dict_Lons = {'long_name':'Longitude of corners of pixels', 'standard_name':'pixels corners longitude',\n",
    "                 'units':'degrees_east', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':Lons}\n",
    "\n",
    "    dict_Lats = {'long_name':'Latitude of corners of pixels', 'standard_name':'pixels corners latitude',\n",
    "                 'units':'degrees_north', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':Lats}\n",
    "\n",
    "    return GOES(dict_Lons), GOES(dict_Lats);\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def corner_size_to_center_size(Field):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Reduce dimension of array from [m,n] to [m-1,n-1]. Where m and n are odd numbers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Field : ndarray\n",
    "        A scalar 2-D array with dimension [m,n].\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Field with size [m-1,n-1]\n",
    "    '''\n",
    "\n",
    "    ny, nx = Field.shape\n",
    "    ny = ny - 1\n",
    "    nx = nx - 1\n",
    "    Field = np.concatenate((Field[:,0:int(nx/2.0)], Field[:,int(nx/2.0)+1:]),axis=1)\n",
    "    Field = np.concatenate((Field[0:int(ny/2.0),:], Field[int(ny/2.0)+1:,:]),axis=0)\n",
    "    return Field;\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def midpoint_in_x(Field, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Calculates the middle value between pixels in X axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Field : ndarray\n",
    "        A scalar 2-D array with dimension [m,n].\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    midpoint : ndarray\n",
    "        A scalar 2-D array with dimension [m,n+1]. Undefined data\n",
    "        are set as -999.99.\n",
    "\n",
    "    '''\n",
    "\n",
    "    Field = np.array(Field,dtype=fmt)\n",
    "    Field = np.column_stack((Field, np.full([Field.shape[0],1],-999.99,dtype=fmt)))\n",
    "    right = np.column_stack((Field[:,1:], np.full([Field.shape[0],1],-999.99,dtype=fmt)))\n",
    "    left = np.column_stack((np.full([Field.shape[0],1],-999.99,dtype=fmt), Field[:,:-1]))\n",
    "    left2 = np.column_stack((np.full([Field.shape[0],2],-999.99,dtype=fmt), Field[:,:-2]))\n",
    "\n",
    "    midpoint = np.where((Field>-400.0)&(left<-400.0),Field-(right-Field)/2.0,-999.99)\n",
    "    midpoint = np.where((Field>-400.0)&(left>-400.0),(left+Field)/2.0,midpoint)\n",
    "    midpoint = np.where((Field<-400.0)&(left>-400.0),left+(left-left2)/2.0,midpoint)\n",
    "    return midpoint;\n",
    "\n",
    "\n",
    "def midpoint_in_y(Field, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Calculates the middle value between pixels in Y axis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Field : ndarray\n",
    "        A scalar 2-D array with dimension [m,n].\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    midpoint : ndarray\n",
    "        A scalar 2-D array with dimension [m+1,n]. Undefined data\n",
    "        are set as -999.99.\n",
    "\n",
    "    '''\n",
    "\n",
    "    Field = np.array(Field,dtype=fmt)\n",
    "    Field = np.vstack((Field, np.full([1,Field.shape[1]],-999.99,dtype=fmt)))\n",
    "    lower = np.vstack((Field[1:,:], np.full([1,Field.shape[1]],-999.99,dtype=fmt)))\n",
    "    upper = np.vstack((np.full([1,Field.shape[1]],-999.99,dtype=fmt), Field[:-1,:]))\n",
    "    upper2 = np.vstack((np.full([2,Field.shape[1]],-999.99,dtype=fmt), Field[:-2,:]))\n",
    "\n",
    "    midpoint = np.where((Field>-400.0)&(upper<-400.0),Field-(lower-Field)/2.0,-999.99)\n",
    "    midpoint = np.where((Field>-400.0)&(upper>-400.0),(upper+Field)/2.0,midpoint)\n",
    "    midpoint = np.where((Field<-400.0)&(upper>-400.0),upper+(upper-upper2)/2.0,midpoint)\n",
    "    return midpoint;\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def calculate_corners(Lons, Lats, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Calculates corners of pixels of the satellite image, from the longitude and latitude\n",
    "    of the center of the pixels.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Lons : ndarray\n",
    "        Scalar 2-D array with the center longitude of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    Lats : ndarray\n",
    "        Scalar 2-D array with the center latitude of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Lons : object\n",
    "        A scalar 2-D array with the longitude of the corners of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    Lats : obejct\n",
    "        A scalar 2-D array with the latitude of the corners of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    try:\n",
    "        assert (isinstance(Lons,GOES)==isinstance(Lats,GOES)==True) or (isinstance(Lons,np.ndarray)==isinstance(Lats,np.ndarray)==True)\n",
    "    except AssertionError:\n",
    "        print('\\nLons and Lats must be GOES class or numpy.ndarray\\n')\n",
    "        return\n",
    "    else:\n",
    "        if isinstance(Lons,GOES) and isinstance(Lats,GOES):\n",
    "            Lons = Lons.data\n",
    "            Lats = Lats.data\n",
    "\n",
    "        Lons = midpoint_in_x(Lons, fmt=fmt)\n",
    "        Lats = midpoint_in_y(Lats, fmt=fmt)\n",
    "\n",
    "        Lons = midpoint_in_y(Lons, fmt=fmt)\n",
    "        Lats = midpoint_in_x(Lats, fmt=fmt)\n",
    "\n",
    "        dict_Lons = {'long_name':'Longitude of corners of pixels', 'standard_name':'pixels corners longitude',\n",
    "                     'units':'degrees_east', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':Lons}\n",
    "\n",
    "        dict_Lats = {'long_name':'Latitude of corners of pixels', 'standard_name':'pixels corners latitude',\n",
    "                     'units':'degrees_north', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':Lats}\n",
    "\n",
    "        return GOES(dict_Lons), GOES(dict_Lats);\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def find_pixel_of_coordinate(Lons, Lats, LonCoord, LatCoord):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Finds the X and Y index of the pixel closest to the required coordinate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Lons : ndarray\n",
    "        A scalar 2-D array with the longitude of the center of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    Lats : ndarray\n",
    "        A scalar 2-D array with the latitude of the center of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    LonCoord : float\n",
    "        Longitude of the required coordinate.\n",
    "\n",
    "    LatCoord : float\n",
    "        Latitude of the required coordinate.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xpix : int\n",
    "        Index on the X axis of the pixel closest to the required coordinate.\n",
    "\n",
    "    ypix : int\n",
    "        Index on the Y axis of the pixel closest to the required coordinate.\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    try:\n",
    "        assert (isinstance(Lons,GOES)==isinstance(Lats,GOES)==True) or (isinstance(Lons,np.ndarray)==isinstance(Lats,np.ndarray)==True)\n",
    "    except AssertionError:\n",
    "        print('\\nLons and Lats must be GOES class or numpy.ndarray\\n')\n",
    "        return\n",
    "    else:\n",
    "        if isinstance(Lons,GOES) and isinstance(Lats,GOES):\n",
    "            Lons = Lons.data\n",
    "            Lats = Lats.data\n",
    "\n",
    "        Dist = np.sqrt( (Lons-LonCoord)**2 + (Lats-LatCoord)**2 )\n",
    "        ypix, xpix = np.unravel_index( np.argmin(Dist, axis=None ), Dist.shape)\n",
    "\n",
    "        return xpix, ypix;\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def cosine_of_solar_zenith_angle(Lons, Lats, DateTime, MinCosTheta=0.0, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "\n",
    "    It calculates the cosine of solar zenith angle (cosine of theta).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Lons : ndarray\n",
    "        A scalar 2-D array with longitude in decimal degrees.\n",
    "\n",
    "    Lats : ndarray\n",
    "        A scalar 2-D array with latitude in decimal degrees.\n",
    "\n",
    "    DateTime: datetime object\n",
    "        Date and Time\n",
    "\n",
    "    MinCosTheta : float, optional, default 0.0\n",
    "        Minimum valid value of the cosine of theta.\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    CosTheta : object\n",
    "        Cosine of solar zenith angle (cosine of theta).\n",
    "\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        assert (isinstance(Lons,GOES)==isinstance(Lats,GOES)==True) or (isinstance(Lons,np.ndarray)==isinstance(Lats,np.ndarray)==True)\n",
    "    except AssertionError:\n",
    "        print('\\nLons and Lats must be GOES class or numpy.ndarray\\n')\n",
    "        return\n",
    "    else:\n",
    "        if isinstance(Lons, GOES) and isinstance(Lats, GOES):\n",
    "            Lons = Lons.data\n",
    "            Lats = Lats.data\n",
    "\n",
    "\n",
    "        JulDay = DateTime.strftime('%j')\n",
    "        Hour = DateTime.strftime('%H')\n",
    "        Minute = DateTime.strftime('%M')\n",
    "\n",
    "        HourDiff = np.where(Lons>-400.0,0.0,np.nan)\n",
    "        CenMer = -165.0+15.0*(np.arange(24))\n",
    "        HourVar = np.arange(-11,13,1)\n",
    "\n",
    "        for idx in range(CenMer.shape[0]):\n",
    "            HourDiff = np.where( (Lons>= CenMer[idx]-7.5)&(Lons<CenMer[idx]+7.5),HourVar[idx],0.0) + HourDiff\n",
    "\n",
    "        Gamma = 2.0*np.pi*(float(JulDay)-1.0)/365.0    # Gamma is in radians\n",
    "        Delta = 0.006918-0.399912*np.cos(Gamma)+0.070257*np.sin(Gamma)-0.006758*np.cos(2*Gamma)+0.000907*np.sin(2*Gamma)-0.002697*np.cos(3*Gamma)+0.00148*np.sin(3*Gamma)  # Solar decline, is in radians.\n",
    "        EqTime = 229.18*(0.0000075+0.001868*np.cos(Gamma)-0.032077*np.sin(Gamma)-0.014615*np.cos(2*Gamma)-0.04089*np.sin(2*Gamma)) # Equation of time, is in minutes.\n",
    "\n",
    "        Omega = (np.pi/12.0)*( float(Hour) + (float(Minute)/60.0) + HourDiff -12.0 + ( (Lons-HourDiff*15.0)/15.0 ) + EqTime/60.0 ) # Hour angle, is in radians.\n",
    "        CosTheta = np.sin(Delta)*np.sin(Lats*np.pi/180.0)+np.cos(Delta)*np.cos(Lats*np.pi/180.0)*np.cos(Omega) # Cosine of theta (zenith angle)\n",
    "        CosTheta[np.where(CosTheta<MinCosTheta)] = np.nan\n",
    "        CosTheta = np.array(CosTheta, dtype=fmt)\n",
    "\n",
    "        dict_CosTheta = {'long_name':'cosine of solar zenith angle', 'standard_name':'cosine of solar zenith angle',\n",
    "                         'units':None, 'undef':np.nan, 'axis':'YX', 'dimensions':('y','x'), 'data':CosTheta}\n",
    "\n",
    "        return GOES(dict_CosTheta);\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def find_pixels_of_region(Lons, Lats, LLLon, URLon, LLLat, URLat):\n",
    "\n",
    "    '''\n",
    "\n",
    "    It finds the corners (pixels index) of the region.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Lons : ndarray\n",
    "        A scalar 2-D array with the longitude of the center of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    Lats : ndarray\n",
    "        A scalar 2-D array with the latitude of the center of the pixels of\n",
    "        the satellite image.\n",
    "\n",
    "    LLLon : float\n",
    "        Lower left longitude of region.\n",
    "\n",
    "    URLon : float\n",
    "        Upper right longitude of region.\n",
    "\n",
    "    LLLat : float\n",
    "        Lower left latitude of region.\n",
    "\n",
    "    URLat : float\n",
    "        Upper right latitude of region.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Limits : numpy.ndarray\n",
    "        Numpy array with the pixels index more close to the region delimited\n",
    "        by LLLon, URLon, LLLat and URLat.\n",
    "        Limits is define as:\n",
    "            Limits = np.array([xmin, xmax, ymin, ymin])\n",
    "            Where:\n",
    "                xmin: pixel index more close to LLLon.\n",
    "\n",
    "                xmax: pixel index more close to URLon.\n",
    "\n",
    "                ymin: pixel index more close to LLLat.\n",
    "\n",
    "                ymax: pixel index more close to URLat.\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    try:\n",
    "        assert (isinstance(Lons,GOES)==isinstance(Lats,GOES)==True) or (isinstance(Lons,np.ndarray)==isinstance(Lats,np.ndarray)==True)\n",
    "    except AssertionError:\n",
    "        print('\\nLons and Lats must be GOES class or numpy.ndarray\\n')\n",
    "        return\n",
    "    else:\n",
    "        if isinstance(Lons, GOES) and isinstance(Lats, GOES):\n",
    "            Lons = Lons.data\n",
    "            Lats = Lats.data\n",
    "\n",
    "        Mask = np.where((Lons>=LLLon)&(Lons<=URLon)&(Lats>=LLLat)&(Lats<=URLat),True,False)\n",
    "        yx = np.argwhere(Mask==True)\n",
    "        ypixmin, ypixmax = np.min(yx[:,0]), np.max(yx[:,0])\n",
    "        xpixmin, xpixmax = np.min(yx[:,1]), np.max(yx[:,1])\n",
    "\n",
    "        Limits = np.array([xpixmin, xpixmax, ypixmin, ypixmax])\n",
    "\n",
    "        return Limits;\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def create_gridmap(Domain, PixResol=2.0, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "\n",
    "    It creates a equirectangular gridmap and return its longitudes and latitudes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Domain : list\n",
    "        List with the coordinates of domain.\n",
    "        The list have four elements: [LeftLon, RightLon, LowerLat, UpperLat]\n",
    "\n",
    "    PixResol : float, optional, default 2.0\n",
    "        Spatial resolution of gridmap in kilometers.\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Lons : object\n",
    "        GOES class with the longitudes of gridmap.\n",
    "\n",
    "    Lats : object\n",
    "        GOES class with the latitude of gridmap.\n",
    "\n",
    "    '''\n",
    "\n",
    "    dict_Lons = {'long_name':'Longitude of gridmap', 'standard_name':'longitude',\n",
    "                    'units':'degrees_east', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':None}\n",
    "    dict_Lats = {'long_name':'Latitude of gridmap', 'standard_name':'latitude',\n",
    "                    'units':'degrees_north', 'undef':-999.99, 'axis':'YX', 'dimensions':('y','x'), 'data':None}\n",
    "    nx = int( np.ceil( (Domain[1] - Domain[0])*111.0/float(PixResol) ) )\n",
    "    ny = int( np.ceil( (Domain[3] - Domain[2])*111.0/float(PixResol) ) )\n",
    "    Lons = np.arange(nx+1,dtype=fmt)*(float(PixResol)/111.0)+Domain[0]\n",
    "    Lats = np.arange(ny+1,dtype=fmt)*(float(PixResol)/111.0)*(-1.0)+Domain[3]\n",
    "    Lons, Lats = np.meshgrid(Lons, Lats)\n",
    "    dict_Lons['data'] = Lons\n",
    "    dict_Lats['data'] = Lats\n",
    "\n",
    "    return GOES(dict_Lons), GOES(dict_Lats);\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def locate_files(path, prefix, datetime_ini, datetime_fin, use_parameter='scan_start_time'):\n",
    "\n",
    "    '''\n",
    "\n",
    "    It locates GOES-16/17 files between initial and final date time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        path of files \n",
    "\n",
    "    prefix : str\n",
    "        Prefix name used to search files\n",
    "\n",
    "    datetime_ini : str or datetime\n",
    "        Initial date time used to search files.\n",
    "        If it is string should have this format 'YYYYmmdd-HHMMSS'\n",
    "\n",
    "    datetime_fin : str or datetime\n",
    "        Final date time used to search files.\n",
    "        If it is string should have this format 'YYYYmmdd-HHMMSS'\n",
    "\n",
    "    use_parameter : str, optional, default 'scan_start_time'\n",
    "        If use_parameter='scan_start_time', then locate files using as\n",
    "        condition the scan start time of files.\n",
    "        If use_parameter='scan_end_time', then locate files using as\n",
    "        condition the scan end time of files.\n",
    "        If use_parameter='both', then locate files using as condition\n",
    "        the scan start time and the scan end time of files.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    return list with name of files.\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    try:\n",
    "        assert (isinstance(datetime_ini,datetime.datetime) or ( isinstance(datetime_ini,str) and len(datetime_ini)==15 )) and (isinstance(datetime_fin,datetime.datetime) or ( isinstance(datetime_fin,str) and len(datetime_fin)==15 ) )\n",
    "    except AssertionError:\n",
    "        print('\\n\\tdatetime_ini and datetime_fin must be datetime.datetime or str with format YYYYmmdd-HHMMSS\\n')\n",
    "        return\n",
    "    else:\n",
    "        if isinstance(datetime_ini,str) and len(datetime_ini)==15:\n",
    "            datetime_ini = datetime.datetime.strptime(datetime_ini,'%Y%m%d-%H%M%S')\n",
    "\n",
    "        if isinstance(datetime_fin,str) and len(datetime_fin)==15:\n",
    "            datetime_fin = datetime.datetime.strptime(datetime_fin,'%Y%m%d-%H%M%S')\n",
    "\n",
    "\n",
    "        l = sorted(glob.glob(path+prefix))\n",
    "\n",
    "        if use_parameter=='scan_start_time':\n",
    "\n",
    "            ini_datetime = []\n",
    "            for file in l:\n",
    "                datetimestr = file[file.find('_s')+2:file.find('_e')]\n",
    "                ini_datetime.append(datetime.datetime.strptime(datetimestr,'%Y%j%H%M%S%f'))\n",
    "\n",
    "\n",
    "            ini_datetime = np.array(ini_datetime)\n",
    "            mask = np.where((ini_datetime>=datetime_ini)&(ini_datetime<datetime_fin),True,False)\n",
    "            l = np.array(l)\n",
    "\n",
    "\n",
    "        elif use_parameter=='scan_end_time':\n",
    "\n",
    "            fin_datetime = []\n",
    "            for file in l:\n",
    "                datetimestr = file[file.find('_e')+2:file.find('_c')]\n",
    "                fin_datetime.append(datetime.datetime.strptime(datetimestr,'%Y%j%H%M%S%f'))\n",
    "\n",
    "            fin_datetime = np.array(fin_datetime)\n",
    "            mask = np.where((fin_datetime>=datetime_ini)&(fin_datetime<datetime_fin),True,False)\n",
    "            l = np.array(l)\n",
    "\n",
    "\n",
    "        elif use_parameter=='both':\n",
    "\n",
    "            ini_datetime = []\n",
    "            fin_datetime = []\n",
    "            for file in l:\n",
    "                datetimestr = file[file.find('_s')+2:file.find('_e')]\n",
    "                ini_datetime.append(datetime.datetime.strptime(datetimestr,'%Y%j%H%M%S%f'))\n",
    "\n",
    "                datetimestr = file[file.find('_e')+2:file.find('_c')]\n",
    "                fin_datetime.append(datetime.datetime.strptime(datetimestr,'%Y%j%H%M%S%f'))\n",
    "\n",
    "\n",
    "            ini_datetime = np.array(ini_datetime)\n",
    "            fin_datetime = np.array(fin_datetime)\n",
    "            mask = np.where((ini_datetime>=datetime_ini)&(fin_datetime<datetime_fin),True,False)\n",
    "            l = np.array(l)\n",
    "\n",
    "\n",
    "        return list(l[mask==True]);\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def accumulate_in_gridmap(Lons, Lats, parameter_lon, parameter_lat, parameter_value=None, dx=200, dy=200, dz=200, show_progress=True, fmt=np.float32):\n",
    "\n",
    "    '''\n",
    "    It accumulates the occurrence or the value of one parameter in equirectangular gridmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Lons : ndarray\n",
    "        2D array with the longitudes of corners of gridmap.\n",
    "\n",
    "    Lats : ndarray\n",
    "        2D array with the latitudes of corners of gridmap.\n",
    "\n",
    "    parameter_lon : object or np.ndarray\n",
    "        Longitude of parameter.\n",
    "\n",
    "    parameter_lat : object or np.ndarray\n",
    "        Latitude of parameter.\n",
    "\n",
    "    parameter_value : object, np.ndarray or None, optional, default None\n",
    "        Value of parameter that will be accumulated in the gridmap.\n",
    "        If parameter_value=None, then just the occurrence of parameter is\n",
    "        accumulated in the gridmap.\n",
    "\n",
    "    dx : int, optional, default 200\n",
    "        Number of pixels, in X axis, in which are split the grid to increase\n",
    "        the speed of processing.\n",
    "\n",
    "    dy : int, optional, default 200\n",
    "        Number of pixels, in Y axis, in which are split the grid to increase\n",
    "        the speed of processing.\n",
    "\n",
    "    dz : int, optional, default 200\n",
    "        Number of elements in which are split the parameter_lon and parameter_lat\n",
    "        to improve the speed of processing.\n",
    "\n",
    "    show_progress : boolean, optional, default True\n",
    "        Enable and disable the visualization of progress of processing.\n",
    "\n",
    "    fmt : dtype, optional, default np.float32\n",
    "        The type of the returns.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accum: object\n",
    "        Parameter accumulated in the gridmap.\n",
    "\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        assert (isinstance(parameter_lon,GOES) and isinstance(parameter_lat,GOES)) or (isinstance(parameter_lon,np.ndarray) and isinstance(parameter_lat,np.ndarray))\n",
    "    except AssertionError:\n",
    "        print('\\n\\tparameter_lon and parameter_lat must be GOES class or np.ndarray\\n')\n",
    "        return\n",
    "    else:\n",
    "\n",
    "        try:\n",
    "            assert (isinstance(Lons,GOES) and isinstance(Lats,GOES)) or (isinstance(Lons,np.ndarray) and isinstance(Lats,np.ndarray))\n",
    "        except AssertionError:\n",
    "            print('\\nLons and Lats must be GOES class or numpy.ndarray\\n')\n",
    "            return\n",
    "        else:\n",
    "\n",
    "            if isinstance(parameter_lon, GOES):\n",
    "                Ltng_Lon = parameter_lon.data\n",
    "                Ltng_Lat = parameter_lat.data\n",
    "            else:\n",
    "                Ltng_Lon = parameter_lon\n",
    "                Ltng_Lat = parameter_lat\n",
    "\n",
    "\n",
    "            try:\n",
    "                assert isinstance(parameter_value,GOES) or isinstance(parameter_value,np.ndarray) or isinstance(parameter_value,type(None))\n",
    "            except AssertionError:\n",
    "                print('\\nparameter_value must be GOES class, numpy.ndarray or None\\n')\n",
    "                return\n",
    "            else:\n",
    "\n",
    "\n",
    "                LongName = 'Parameter accumulated in the gridmap'\n",
    "                StandardName = 'Parameter accumulated'\n",
    "                Units = None\n",
    "                TimeBounds = None\n",
    "\n",
    "\n",
    "                if isinstance(parameter_value, GOES):\n",
    "                    Ltng_Par = parameter_value.data\n",
    "                elif isinstance(parameter_value,np.ndarray):\n",
    "                    Ltng_Par = parameter_value\n",
    "                else:\n",
    "                    Ltng_Par = np.full(Ltng_Lon.shape[0],1.0,dtype=fmt)\n",
    "                    LongName = 'Accumulated occurrences in the gridmap'\n",
    "                    StandardName = 'Accumulated occurrences'\n",
    "\n",
    "\n",
    "                if isinstance(Lons, GOES)==True and isinstance(Lats, GOES)==True:\n",
    "                    Lons = Lons.data\n",
    "                    Lats = Lats.data\n",
    "\n",
    "\n",
    "                dict_Field = {'long_name':LongName, 'standard_name':StandardName,\n",
    "                              'units':Units, 'undef':np.nan, 'axis':'YX',\n",
    "                              'time_bounds':TimeBounds, 'dimensions':('y','x'), 'data':None}\n",
    "\n",
    "\n",
    "                LonsCen = Lons[0,:-1]+(Lons[0,1]-Lons[0,0])/2.0\n",
    "                LatsCen = Lats[:-1,0]+(Lats[1,0]-Lats[0,0])/2.0\n",
    "                LonsCen, LatsCen = np.meshgrid(LonsCen, LatsCen)\n",
    "\n",
    "                Mask = np.where((Ltng_Lon>=Lons[0,0])&(Ltng_Lon<=Lons[0,-1])&(Ltng_Lat>=Lats[-1,0])&(Ltng_Lat<=Lats[0,0]),True,False)\n",
    "                Ltng_Lon = np.delete(Ltng_Lon, np.where(Mask==False))\n",
    "                Ltng_Lat = np.delete(Ltng_Lat, np.where(Mask==False))\n",
    "                Ltng_Par = np.delete(Ltng_Par, np.where(Mask==False))\n",
    "                if show_progress == True:\n",
    "                    print('    There are {:.0f} occurrences inside gridmap'.format(Ltng_Lon.shape[0]))\n",
    "\n",
    "\n",
    "                accum = np.full(LonsCen.shape,0,dtype=fmt)\n",
    "\n",
    "                if Ltng_Lon.shape[0] == 0:\n",
    "\n",
    "                    dict_Field['data'] = accum\n",
    "                    return GOES(dict_Field);\n",
    "\n",
    "                else:\n",
    "\n",
    "                    ysize, xsize = Lons.shape\n",
    "                    xidx = np.arange(0,xsize+dx-1,dx-1)\n",
    "                    yidx = np.arange(0,ysize+dy-1,dy-1)\n",
    "                    NSlides = (xidx.shape[0]-1)*(yidx.shape[0]-1)\n",
    "                    Slide = 0\n",
    "\n",
    "\n",
    "                    for j in range(len(yidx)-1):\n",
    "                        for i in range(len(xidx)-1):\n",
    "                            LonsCut = Lons[yidx[j]:yidx[j+1]+1,xidx[i]:xidx[i+1]+1]\n",
    "                            LonsCutMin, LonsCutMax = LonsCut.min(), LonsCut.max()\n",
    "                            LonsCutCen = LonsCen[yidx[j]:yidx[j+1],xidx[i]:xidx[i+1]]\n",
    "\n",
    "                            LatsCut = Lats[yidx[j]:yidx[j+1]+1,xidx[i]:xidx[i+1]+1]\n",
    "                            LatsCutMin, LatsCutMax = LatsCut.min(), LatsCut.max()\n",
    "                            LatsCutCen = LatsCen[yidx[j]:yidx[j+1],xidx[i]:xidx[i+1]]\n",
    "\n",
    "                            # delete occurrences out of Sub-Area\n",
    "                            Mask = np.where((Ltng_Lon>=LonsCutMin)&(Ltng_Lon<=LonsCutMax)&(Ltng_Lat>=LatsCutMin)&(Ltng_Lat<=LatsCutMax),True,False)\n",
    "                            Ltng_Lon2 = np.delete(Ltng_Lon, np.where(Mask==False))\n",
    "                            Ltng_Lat2 = np.delete(Ltng_Lat, np.where(Mask==False))\n",
    "                            Ltng_Par2 = np.delete(Ltng_Par, np.where(Mask==False))\n",
    "\n",
    "\n",
    "                            if Ltng_Lon2.shape[0]>0:\n",
    "                                zsize = Ltng_Lon2.shape[0]\n",
    "                                zidx = np.arange(0,zsize+dz,dz)\n",
    "                                for k in range(len(zidx)-1):\n",
    "                                    Ltng_Lon3 = Ltng_Lon2[zidx[k]:zidx[k+1]]\n",
    "                                    Ltng_Lat3 = Ltng_Lat2[zidx[k]:zidx[k+1]]\n",
    "                                    Ltng_Par3 = Ltng_Par2[zidx[k]:zidx[k+1]]\n",
    "\n",
    "                                    Dist = np.sqrt( (LonsCutCen-Ltng_Lon3[:,None,None])**2 + (LatsCutCen-Ltng_Lat3[:,None,None])**2 )\n",
    "                                    Mins = np.min(Dist.reshape((Dist.shape[0],Dist.shape[1]*Dist.shape[2])), axis=1)[:,None,None]\n",
    "                                    accum[yidx[j]:yidx[j+1],xidx[i]:xidx[i+1]] = np.sum(np.where(Dist==Mins, 1, 0)*Ltng_Par3[:,None,None], axis=0) + accum[yidx[j]:yidx[j+1],xidx[i]:xidx[i+1]]\n",
    "\n",
    "                            Slide = Slide + 1\n",
    "                            if show_progress == True:\n",
    "                                print('    processing {:3.0f}%'.format(100.0*(Slide)/NSlides), end='\\r', flush=True)\n",
    "                                if  Slide == NSlides:\n",
    "                                    print('\\b')\n",
    "\n",
    "                    accum = np.array(accum, dtype=fmt)\n",
    "                    dict_Field['data'] = accum\n",
    "\n",
    "                    return GOES(dict_Field);\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ebezerra/atmoseer/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RRQPE': <class 'netCDF4._netCDF4.Variable'>\n",
      "int16 RRQPE(y, x)\n",
      "    _FillValue: -1\n",
      "    long_name: ABI L2+ Rainfall Rate - Quantitative Prediction Estimate\n",
      "    standard_name: rainfall_rate\n",
      "    _Unsigned: true\n",
      "    valid_range: [ 0 -6]\n",
      "    scale_factor: 0.00152602\n",
      "    add_offset: 0.0\n",
      "    units: mm h-1\n",
      "    resolution: y: 0.000056 rad x: 0.000056 rad\n",
      "    coordinates: latitude retrieval_local_zenith_angle quantitative_local_zenith_angle solar_zenith_angle t y x\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: latitude: point (good quality pixel produced) retrieval_local_zenith_angle: point (good or degraded quality pixel produced) quantitative_local_zenith_angle: sum (good quality pixel produced) solar_zenith_angle: sum (good quality pixel produced) t: point area: point\n",
      "    ancillary_variables: DQF\n",
      "unlimited dimensions: \n",
      "current shape = (5424, 5424)\n",
      "filling on, 'DQF': <class 'netCDF4._netCDF4.Variable'>\n",
      "int8 DQF(y, x)\n",
      "    _FillValue: -1\n",
      "    long_name: ABI L2+ Rainfall Rate - Quantitative Prediction Estimate data quality flags\n",
      "    standard_name: status_flag\n",
      "    _Unsigned: true\n",
      "    valid_range: [  0 127]\n",
      "    units: 1\n",
      "    coordinates: latitude retrieval_local_zenith_angle quantitative_local_zenith_angle solar_zenith_angle t y x\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: latitude: point retrieval_local_zenith_angle: point quantitative_local_zenith_angle: point solar_zenith_angle: point t: point area: point\n",
      "    flag_masks: [ 1  1  2  4  8 16 32 64]\n",
      "    flag_values: [ 0  1  2  4  8 16 32 64]\n",
      "    flag_meanings: good_quality_qf bad_quality_qf degraded_due_to_LZA_or_latitude_threshold_exceeded_qf invalid_due_to_bad_or_missing_brightness_temp_data_or_1st_rain_predictor_fails_validation_qf invalid_due_to_bad_or_missing_brightness_temp_data_or_2nd_rain_predictor_fails_validation_qf invalid_due_to_bad_or_missing_brightness_temp_data_or_1st_rain_rate_predictor_fails_validation_qf invalid_due_to_bad_or_missing_brightness_temp_data_or_2nd_rain_rate_predictor_fails_validation_qf invalid_due_to_missing_retrieval_coefficients_qf\n",
      "    number_of_qf_values: 8\n",
      "    percent_good_quality_qf: 0.8798183\n",
      "    percent_bad_quality_qf: 0.2486141\n",
      "    percent_degraded_due_to_LZA_or_latitude_threshold_exceeded_qf: 0.2486141\n",
      "    percent_invalid_due_to_bad_or_missing_brightness_temp_data_or_1st_rain_predictor_fails_validation_qf: 0.1284587\n",
      "    percent_invalid_due_to_bad_or_missing_brightness_temp_data_or_2nd_rain_predictor_fails_validation_qf: 0.1284587\n",
      "    percent_invalid_due_to_bad_or_missing_brightness_temp_data_or_1st_rain_rate_predictor_fails_validation_qf: 0.1284587\n",
      "    percent_invalid_due_to_bad_or_missing_brightness_temp_data_or_2nd_rain_rate_predictor_fails_validation_qf: 0.1284587\n",
      "    percent_invalid_due_to_missing_retrieval_coefficients_qf: 0.1284587\n",
      "unlimited dimensions: \n",
      "current shape = (5424, 5424)\n",
      "filling on, 't': <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 t()\n",
      "    long_name: J2000 epoch mid-point between the start and end image scan in seconds\n",
      "    standard_name: time\n",
      "    units: seconds since 2000-01-01 12:00:00\n",
      "    axis: T\n",
      "    bounds: time_bounds\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'y': <class 'netCDF4._netCDF4.Variable'>\n",
      "int16 y(y)\n",
      "    scale_factor: -5.6e-05\n",
      "    add_offset: 0.151844\n",
      "    units: rad\n",
      "    axis: Y\n",
      "    long_name: GOES fixed grid projection y-coordinate\n",
      "    standard_name: projection_y_coordinate\n",
      "unlimited dimensions: \n",
      "current shape = (5424,)\n",
      "filling on, default _FillValue of -32767 used, 'x': <class 'netCDF4._netCDF4.Variable'>\n",
      "int16 x(x)\n",
      "    scale_factor: 5.6e-05\n",
      "    add_offset: -0.151844\n",
      "    units: rad\n",
      "    axis: X\n",
      "    long_name: GOES fixed grid projection x-coordinate\n",
      "    standard_name: projection_x_coordinate\n",
      "unlimited dimensions: \n",
      "current shape = (5424,)\n",
      "filling on, default _FillValue of -32767 used, 'time_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time_bounds(number_of_time_bounds)\n",
      "    long_name: Scan start and end times in seconds since epoch (2000-01-01 12:00:00)\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'goes_imager_projection': <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 goes_imager_projection()\n",
      "    long_name: GOES-R ABI fixed grid projection\n",
      "    grid_mapping_name: geostationary\n",
      "    perspective_point_height: 35786023.0\n",
      "    semi_major_axis: 6378137.0\n",
      "    semi_minor_axis: 6356752.31414\n",
      "    inverse_flattening: 298.2572221\n",
      "    latitude_of_projection_origin: 0.0\n",
      "    longitude_of_projection_origin: -75.0\n",
      "    sweep_angle_axis: x\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of -2147483647 used, 'y_image': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 y_image()\n",
      "    long_name: GOES-R fixed grid projection y-coordinate center of image\n",
      "    standard_name: projection_y_coordinate\n",
      "    units: rad\n",
      "    axis: Y\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'y_image_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 y_image_bounds(number_of_image_bounds)\n",
      "    long_name: GOES-R fixed grid projection y-coordinate north/south extent of image\n",
      "    units: rad\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'x_image': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 x_image()\n",
      "    long_name: GOES-R fixed grid projection x-coordinate center of image\n",
      "    standard_name: projection_x_coordinate\n",
      "    units: rad\n",
      "    axis: X\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'x_image_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 x_image_bounds(number_of_image_bounds)\n",
      "    long_name: GOES-R fixed grid projection x-coordinate west/east extent of image\n",
      "    units: rad\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'nominal_satellite_subpoint_lat': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 nominal_satellite_subpoint_lat()\n",
      "    long_name: nominal satellite subpoint latitude (platform latitude)\n",
      "    standard_name: latitude\n",
      "    _FillValue: -999.0\n",
      "    units: degrees_north\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'nominal_satellite_subpoint_lon': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 nominal_satellite_subpoint_lon()\n",
      "    long_name: nominal satellite subpoint longitude (platform longitude)\n",
      "    standard_name: longitude\n",
      "    _FillValue: -999.0\n",
      "    units: degrees_east\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'nominal_satellite_height': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 nominal_satellite_height()\n",
      "    long_name: nominal satellite height above GRS 80 ellipsoid (platform altitude)\n",
      "    standard_name: height_above_reference_ellipsoid\n",
      "    _FillValue: -999.0\n",
      "    units: km\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'geospatial_lat_lon_extent': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 geospatial_lat_lon_extent()\n",
      "    long_name: geospatial latitude and longitude references\n",
      "    geospatial_westbound_longitude: -156.2995\n",
      "    geospatial_northbound_latitude: 81.3282\n",
      "    geospatial_eastbound_longitude: 6.2995\n",
      "    geospatial_southbound_latitude: -81.3282\n",
      "    geospatial_lat_center: 0.0\n",
      "    geospatial_lon_center: -75.0\n",
      "    geospatial_lat_nadir: 0.0\n",
      "    geospatial_lon_nadir: -75.0\n",
      "    geospatial_lat_units: degrees_north\n",
      "    geospatial_lon_units: degrees_east\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'total_pixels_with_rain': <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 total_pixels_with_rain()\n",
      "    long_name: number of good quality pixels where it is raining (i.e., where rainfall_rate is > 1 mm h-1)\n",
      "    _FillValue: -1\n",
      "    units: count\n",
      "    coordinates: accounted_rainfall_rate latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: accounted_rainfall_rate: sum latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: sum (interval: 0.000056 rad comment: good quality pixels only) where rain\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'total_rain_volume': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 total_rain_volume()\n",
      "    long_name: sum of rainfall rate for good quality pixels where it is raining (i.e., where rainfall_rate is > 1 mm h-1)\n",
      "    _FillValue: -999.0\n",
      "    units: mm h-1\n",
      "    coordinates: accounted_rainfall_rate latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: accounted_rainfall_rate: sum latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: sum (interval: 0.000056 rad comment: good quality pixels only) where rain\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'total_pixels_with_successful_retrieval': <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 total_pixels_with_successful_retrieval()\n",
      "    long_name: number of good rainfall rate algorithm retrievals\n",
      "    _FillValue: -1\n",
      "    units: count\n",
      "    coordinates: latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: sum (interval: 0.000056 rad comment: good quality pixels only)\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'rainfall_rate_outlier_pixel_count': <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 rainfall_rate_outlier_pixel_count()\n",
      "    long_name: number of rainfall rate pixels whose value is outside valid measurement range\n",
      "    _FillValue: -1\n",
      "    units: count\n",
      "    coordinates: accounted_rainfall_rate latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: accounted_rainfall_rate: sum latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: sum (interval: 0.000056 rad comment: good quality pixels whose values are outside valid measurement range only) where rain\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'minimum_rainfall_rate': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 minimum_rainfall_rate()\n",
      "    long_name: minimum rainfall rate\n",
      "    standard_name: rainfall_rate\n",
      "    _FillValue: -999.0\n",
      "    valid_range: [  1. 100.]\n",
      "    units: mm h-1\n",
      "    coordinates: accounted_rainfall_rate latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: accounted_rainfall_rate: sum latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: minimum (interval: 0.000056 rad comment: good quality pixels only) where rain\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'maximum_rainfall_rate': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 maximum_rainfall_rate()\n",
      "    long_name: maximum rainfall rate\n",
      "    standard_name: rainfall_rate\n",
      "    _FillValue: -999.0\n",
      "    valid_range: [  1. 100.]\n",
      "    units: mm h-1\n",
      "    coordinates: accounted_rainfall_rate latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: accounted_rainfall_rate: sum latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: maximum (interval: 0.000056 rad comment: good quality pixels only) where rain\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'mean_rainfall_rate': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 mean_rainfall_rate()\n",
      "    long_name: mean rainfall rate\n",
      "    standard_name: rainfall_rate\n",
      "    _FillValue: -999.0\n",
      "    valid_range: [  1. 100.]\n",
      "    units: mm h-1\n",
      "    coordinates: accounted_rainfall_rate latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: accounted_rainfall_rate: sum latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: mean (interval: 0.000056 rad comment: good quality pixels only) where rain\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'standard_deviation_rainfall_rate': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 standard_deviation_rainfall_rate()\n",
      "    long_name: standard deviation of rainfall rate values\n",
      "    standard_name: rainfall_rate\n",
      "    _FillValue: -999.0\n",
      "    units: mm h-1\n",
      "    coordinates: accounted_rainfall_rate latitude quantitative_local_zenith_angle solar_zenith_angle t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: accounted_rainfall_rate: sum latitude: sum quantitative_local_zenith_angle: sum solar_zenith_angle: sum t: sum area: standard_deviation (interval: 0.000056 rad comment: good quality pixels only) where rain\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'algorithm_dynamic_input_data_container': <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 algorithm_dynamic_input_data_container()\n",
      "    long_name: container for filenames of dynamic algorithm input data\n",
      "    input_ABI_L2_brightness_temperature_band_8_2km_data: OR_L2-CMIPF-M6C08_G16_s20193371500201_e20193371509509_c*.nc\n",
      "    input_ABI_L2_brightness_temperature_band_10_2km_data: OR_L2-CMIPF-M6C10_G16_s20193371500201_e20193371509509_c*.nc\n",
      "    input_ABI_L2_brightness_temperature_band_11_2km_data: OR_L2-CMIPF-M6C11_G16_s20193371500201_e20193371509509_c*.nc\n",
      "    input_ABI_L2_brightness_temperature_band_14_2km_data: OR_L2-CMIPF-M6C14_G16_s20193371500201_e20193371509509_c*.nc\n",
      "    input_ABI_L2_brightness_temperature_band_15_2km_data: OR_L2-CMIPF-M6C15_G16_s20193371500201_e20193371509509_c*.nc\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of -2147483647 used, 'processing_parm_version_container': <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 processing_parm_version_container()\n",
      "    long_name: container for processing parameter filenames\n",
      "    L2_processing_parm_version: OR-PARM-RRPE_v01r00.zip, OR-PARM-SEMISTATIC_v01r00.zip, OR-PARM-AUXILIARY_v01r00.zip\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of -2147483647 used, 'algorithm_product_version_container': <class 'netCDF4._netCDF4.Variable'>\n",
      "int32 algorithm_product_version_container()\n",
      "    long_name: container for algorithm package filename and product version\n",
      "    algorithm_version: OR_ABI-L2-ALG-RRQPE_v01r00.zip\n",
      "    product_version: v01r00\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of -2147483647 used, 'retrieval_local_zenith_angle': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 retrieval_local_zenith_angle()\n",
      "    long_name: threshold angle between the line of sight to the satellite and the local zenith at the observation target for good or degraded quality rainfall rate QPE data production\n",
      "    standard_name: platform_zenith_angle\n",
      "    units: degree\n",
      "    bounds: retrieval_local_zenith_angle_bounds\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'quantitative_local_zenith_angle': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 quantitative_local_zenith_angle()\n",
      "    long_name: threshold angle between the line of sight to the satellite and the local zenith at the observation target for good quality rainfall rate QPE data production\n",
      "    standard_name: platform_zenith_angle\n",
      "    units: degree\n",
      "    bounds: quantitative_local_zenith_angle_bounds\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'retrieval_local_zenith_angle_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 retrieval_local_zenith_angle_bounds(number_of_LZA_bounds)\n",
      "    long_name: local zenith angle degree range where good or degraded quality rainfall rate QPE data is produced\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'quantitative_local_zenith_angle_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 quantitative_local_zenith_angle_bounds(number_of_LZA_bounds)\n",
      "    long_name: local zenith angle degree range where good quality rainfall rate QPE data is produced\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'solar_zenith_angle': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 solar_zenith_angle()\n",
      "    long_name: threshold angle between the line of sight to the sun and the local zenith at the observation target for good quality rainfall rate QPE data production\n",
      "    standard_name: solar_zenith_angle\n",
      "    units: degree\n",
      "    bounds: solar_zenith_angle_bounds\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'solar_zenith_angle_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 solar_zenith_angle_bounds(number_of_SZA_bounds)\n",
      "    long_name: solar zenith angle degree range where good quality rainfall rate QPE data is produced\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'latitude': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 latitude()\n",
      "    long_name: threshold latitude for good quality rainfall rate QPE data production\n",
      "    standard_name: latitude\n",
      "    units: degrees_north\n",
      "    bounds: latitude_bounds\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'latitude_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 latitude_bounds(number_of_lat_bounds)\n",
      "    long_name: latitude range where good quality rainfall rate QPE data is produced\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'accounted_rainfall_rate': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 accounted_rainfall_rate()\n",
      "    long_name: threshold rainfall rate for including pixel in image statistics\n",
      "    standard_name: rainfall_rate\n",
      "    units: mm h-1\n",
      "    bounds: accounted_rainfall_rate_bounds\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'accounted_rainfall_rate_bounds': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 accounted_rainfall_rate_bounds(number_of_rainfall_rate_bounds)\n",
      "    long_name: rainfall rate range for including pixel in image statistics\n",
      "unlimited dimensions: \n",
      "current shape = (2,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used, 'percent_uncorrectable_GRB_errors': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 percent_uncorrectable_GRB_errors()\n",
      "    long_name: percent data lost due to uncorrectable GRB errors\n",
      "    _FillValue: -999.0\n",
      "    valid_range: [0. 1.]\n",
      "    units: percent\n",
      "    coordinates: t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: t: sum area: sum (uncorrectable GRB errors only)\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on, 'percent_uncorrectable_L0_errors': <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 percent_uncorrectable_L0_errors()\n",
      "    long_name: percent data lost due to uncorrectable L0 errors\n",
      "    _FillValue: -999.0\n",
      "    valid_range: [0. 1.]\n",
      "    units: percent\n",
      "    coordinates: t y_image x_image\n",
      "    grid_mapping: goes_imager_projection\n",
      "    cell_methods: t: sum area: sum (uncorrectable L0 errors only)\n",
      "unlimited dimensions: \n",
      "current shape = ()\n",
      "filling on}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        ...,\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --],\n",
       "        [--, --, --, ..., --, --, --]],\n",
       "  mask=[[ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True],\n",
       "        [ True,  True,  True, ...,  True,  True,  True]],\n",
       "  fill_value=65535,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../data/goes16/OR_ABI-L2-RRQPEF-M6_G16_s20193371500201_e20193371509509_c20193371510004.nc'\n",
    "# filename = '../data/goes16/prec_acum_ret_202203312300.nc'\n",
    "\n",
    "ds = open_dataset(filename)\n",
    "# print(ds)\n",
    "\n",
    "from netCDF4 import Dataset      # Read / Write NetCDF4 files\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "# Open the GOES-R image\n",
    "# Download files at this link: http://home.chpc.utah.edu/~u0553130/Brian_Blaylock/cgi-bin/goes16_download.cgi\n",
    "file = Dataset(filename)\n",
    "\n",
    "print(file.variables)\n",
    "\n",
    "# Get the pixel values\n",
    "data = file.variables['RRQPE'][:]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<class '__main__.GOES'>\n",
       " \n",
       " Keys:\n",
       "    long_name                     : ABI L2+ Rainfall Rate - Quantitative Prediction ...\n",
       "    standard_name                 : rainfall_rate\n",
       "    units                         : mm h-1\n",
       "    undef                         : nan\n",
       "    axis                          : YX\n",
       "    dimensions                    : (y, x)\n",
       "    t                             <class '__main__.GOES'>\n",
       "    time_bounds                   <class '__main__.GOES'>\n",
       "    pixels_limits                 (4) int64\n",
       "    data                          (5424, 5424) float32,\n",
       " <class '__main__.GOES'>\n",
       " \n",
       " Keys:\n",
       "    long_name                     : Longitude of center of pixels\n",
       "    standard_name                 : pixels center longitude\n",
       "    units                         : degrees_east\n",
       "    undef                         : -999.99\n",
       "    axis                          : YX\n",
       "    dimensions                    : (y, x)\n",
       "    data                          (5424, 5424) float32,\n",
       " <class '__main__.GOES'>\n",
       " \n",
       " Keys:\n",
       "    long_name                     : Latitude of center of pixels\n",
       "    standard_name                 : pixels center latitude\n",
       "    units                         : degrees_north\n",
       "    undef                         : -999.99\n",
       "    axis                          : YX\n",
       "    dimensions                    : (y, x)\n",
       "    data                          (5424, 5424) float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.image('RRQPE', lonlat='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RRQPE, LonCen, LatCen = ds.image('RRQPE', lonlat='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4192 3899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Coordenadas da estação do Forte de Copacabana\n",
    "lat = -22.98833333\n",
    "lon = -43.19055555\n",
    "\n",
    "x, y = find_pixel_of_coordinate(LonCen, LatCen, lon, lat)\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(RRQPE.data[y,x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5424, 5424)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RRQPE.data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmoseer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
