# AtmoSeer

## About

This project provides a pipeline to build rainfall forecast models using 1D Convolutional Neural Networks. The pipeline can be configured with different meteorological data sources.

## Install

In the root directory of this repository, type the following command (you must have conda installed in your system):

./setup.sh

## Project pipeline

The project pipeline is defined as a sequence of three steps: (1) data import, (2) data pre-processing and (3) model generation. These steps are implemented as Python scripts in the `./src` directory.

### Data import scripts

In the project there are 3 different data import scripts, for COR stations, INMET stations and Radiosonde. They are responsible for generating the datasets that will be used for training the nowcasting model. All datasets generated by the above scripts described in this section will be stored in the `./data` folder.

#### Script **_import_cor.py_** 

This script has four command line arguments:

- `-s` or `--sta` that define which station will be selected. You have to provide the weather station of interest by name: alto_da_boa_vista, guaratiba, iraja, jardim_botanico, riocentro, santa_cruz, sao_cristovao, vidigal. 
- `-a` or `--all` which if filled with 1 indicates that they will be importing the data of all stations.
- `-b` or `--begin` and `-e` or `--end` which can be filled with the interval of years for importing the data (The default interval for data import period is from 1997 to 2022). 

Example 1:

`python import_cor.py -s são_cristovao`

The above command imports the São Cristóvão station dataset into the project data folder.

Example 2:

`python import_cor.py -a 1 -b 2000 -e 2015`

The above command imports all the stations in the period from 2000 to 2015.


#### Script **_import_inmet.py_** 

This script has four command line arguments:

-  `-s` or `--sta`, which defines which station will be selected. You must provide the weather stations using their code. The possible codes are A652 (Forte de Copacabana), A636 (Jacarepagua), A621 (Vila Militar), A602 (Marambaia).
- `-a` or `--all` which if filled with 1 indicates that data from all stations will be imported.
- `-b` or `--begin` and `-e` or `--end` which can be filled with the interval of years for importing the data (The default interval for data import period is from 1997 to 2022).
- -t <token> defines the INMET API token to be used to access data.

Example 1:

`python import_inmet.py -s A652 -t <token>`

The above command imports the observations from station with code A652, saving the dowloaded content to a file named 'A652_1997_2022.csv'

Example 2:

`python import_inmet.py -a 1 -b 1999 -e 2017 -t <token>`

The command imports the observations from all stations between 1999 to 2017 will be imported.


#### Script **_import_rad.py_**

This script has two command line arguments:

- `-b` or `--begin` and `-e` or `--end` which can be filled in with the year interval for data import (The default interval for data import period is from 1997 to 2022). 

When running it the Galeão Airport radiosonde observations dataset will be imported.

Example:

`python import_rad.py`

The above command imports Galeão Airport radiosonde (SGBL) observations into the project data folder.

#### Script **_index_rad.py_** 

This script has no arguments. It will generate the atmospheric instability indexes for the data imported by the script **_import_rad.py_**.

Example:

`python index_rad.py`

Data from the Galeão Airport radiosonde will be used to calculate atmospheric instability indexes, generating a new dataset in the project's data folder.


### Pre Processing
The preprocessing script is responsible for performing several operations on the original dataset, such as creating variables or aggregating data, which can be interesting for model training and its final result. To run the preprocessing script you need to run the `Python pre_processing.py` command. The pre_processing code has 3 possible arguments, with only the first being required.

The arguments are:
 - `-f` or `--file` Mandatory argument, represents the name of the data file that will be used as a base for the model. It must be the same as the name of one of the files present in the *Data* folder of the project.
 - `-d` or `--data` Defines the data sources that will be used to assemble the dataset.
  Uses the format of defined acronyms in the text
    - E : Weather station only
    - E-N : Weather station and numerical model
    - E-R : Weather station and radiosonde
    - E-N-R : Weather station, numerical model and radiosonde
- `-s` or `--sta` Defines how many nearby stations will be added to the dataset
Execution Example:
  
  `python pre_processing.py -f 'RIO DE JANEIRO - FORTE DE COPACABANA_1997_2022' -d 'E-N-R' -s 5'`

A dataset will be created from the Forte de Copacabana station, with the aggregation of data from the 5 nearest meteorological stations, using the data sources: numerical model and radiosonde.


### Model generation
The model generation script is responsible for performing the training and exporting the results obtained by the model after testing. It can be executed through the command `python creates_modelo.py`, which needs two arguments `-f` or `-file` which receives the name of one of the datasets generated from pre-processing and `-r` or ` --reg` which defines the architecture that will be used.
Execution Example:

`python creates_modelo.py -f 'RIO DE JANEIRO - FORTE DE COPACABANA_E-N-R_EI+5NN'`

An ordinal classification model will be created based on the already processed dataset from the Forte de Copacabana station.

`python creates_modelo.py -f 'RIO DE JANEIRO - FORTE DE COPACABANA_E-N-R_EI+5NN' -r 1`

A regression model will be created based on the already processed data set of the Forte de Copacabana station

# System test example

Import : `python import_inmet.py -s A652`

Pre processing : `python pre_processing.py -f 'RIO DE JANEIRO - FORTE DE COPACABANA' -d 'E-N-R' -s 5 `

Model generation : `python creates_modelo.py -f 'RIO DE JANEIRO - FORTE DE COPACABANA_E-N-R_EI+5NN' -r 1`
