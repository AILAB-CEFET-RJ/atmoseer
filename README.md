# AtmoSeer

## About

This project provides a pipeline to build rainfall forecast models. The pipeline can be configured with different meteorological data sources.

## Install

In the root directory of this repository, type the following command (you must have conda installed in your system):

./setup.sh

## Project pipeline

The project pipeline is defined as a sequence of three steps: (1) data retrieving, (2) data pre-processing and (3) model training. These steps are implemented as Python scripts in the `./src` directory.

#### Data retrieving scripts

All datasets retrieved and/or generated by the scripts will be stored in the `./data` folder.

- **_retrieve_ws_cor.py_**: This script retrieves all the stations observations for a given period.
- **_retrieve_ws_inmet.py_**: This script retrieves the observations from a given weather station.
- **_retrieve_sounding.py_**: this script retrieves atmospheric sounding data for a given perior. 


#### Script **_gen_sounding_indices.py_** 

This script will generate the atmospheric instability indexes for the data retrieveed by the script **_retrieve_sounding.py_**. Data from the SBGL sounding (located at the Gale√£o Airport, Rio de Janeiro - Brazil) will be used to calculate atmospheric instability indexes, generating a new dataset in CSV format. This new dataset contains one entry per sounding probe. SBGL sounding station produces two probes per day (at 00:00h and 12:00h UTC). Each entry contains the values of the computed instability indices for one probe. The following instability indices are computed:

- CAPE
- CIN
- Lift
- k
- Total totals
- Show alter

#### Pre Processing
The preprocessing script is responsible for performing several operations on the original dataset, such as creating variables or aggregating data, which can be interesting for model training and its final result. To run the preprocessing script you need to run the `Python pre_processing.py` command. The pre_processing code has 3 possible arguments, with only the first being required.

The arguments are:
 - `-f` or `--file` Mandatory argument, represents the name of the data file that will be used as a base for the model. It must be the same as the name of one of the files present in the *Data* folder of the project.
 - `-d` or `--data` Defines the data sources that will be used to assemble the dataset. The possible options are the following:
    - 'E': Weather station only
    - 'E-N': Weather station and numerical model
    - 'E-R': Weather station and radiosonde
    - 'E-N-R': Weather station, numerical model, and radiosonde
- `-n` or `--neighbors` Defines how many nearby meteorological stations will be used to enrich the dataset

Usage example:
  
  `python preprocess_datasources.py -f 'RIO DE JANEIRO - FORTE DE COPACABANA_1997_2022' -d 'E-N-R' -s 5'`

Usage example:
  
  `python preprocessing.py -f 'RIO DE JANEIRO - FORTE DE COPACABANA_1997_2022' -d 'E-N-R' -s 5'`

The above command creates a dataset considering the Forte de Copacabana station as center, with the aggregation of data from the 5 nearest meteorological stations, using the data sources: numerical model and radiosonde.

The above command creates a dataset considering the Forte de Copacabana station as center, with the aggregation of data from the 5 nearest meteorological stations, using the data sources: numerical model and radiosonde.

#### Model training script
The model generation script is responsible for performing the training and exporting the results obtained by the model after testing. It can be executed through the command `Python creates_modelo.py`, which needs two arguments `-f` or `-file` which receives the name of one of the datasets generated from pre-processing and `-r` or ` --reg` which defines the architecture that will be used.
